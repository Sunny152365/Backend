from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import time

def get_driver():
    """
    ì…€ë ˆë‹ˆì›€ í¬ë¡¬ ë“œë¼ì´ë²„ ì´ˆê¸°í™” (ê³µí†µ)
    """
    options = Options()
    options.add_argument('--headless')  # GUI ì—†ì´ ì‹¤í–‰
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument('--disable-gpu')
    options.add_argument('--lang=ko_KR')
    # ğŸ’¡ ë„¤ì´ë²„ ì ‘ê·¼ ì°¨ë‹¨ ìš°íšŒìš© User-Agent
    options.add_argument(
        'user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) '
        'AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36'
    )
    return webdriver.Chrome(options=options)

def crawl_news(keyword):
    """
    ë„¤ì´ë²„ ë‰´ìŠ¤ì—ì„œ í‚¤ì›Œë“œ ê´€ë ¨ ì œëª©ì„ 10ê°œ í¬ë¡¤ë§
    """
    print(f"[í¬ë¡¤ë§ ì‹œì‘] ë‰´ìŠ¤ í‚¤ì›Œë“œ: {keyword}")
    driver = None
    try:
        driver = get_driver()
        search_url = f"https://search.naver.com/search.naver?where=news&query={keyword}"
        driver.get(search_url)

        WebDriverWait(driver, 10).until(
            EC.presence_of_all_elements_located(
                (By.CSS_SELECTOR, 'span.sds-comps-text-type-headline1')
            )
        )

        titles = driver.find_elements(By.CSS_SELECTOR, 'span.sds-comps-text-type-headline1')
        print(f"[ë‰´ìŠ¤ ì œëª© ê°œìˆ˜] {len(titles)}ê°œ ì°¾ìŒ")
        return [title.text.strip() for title in titles[:10]]

    except Exception as e:
        print(f"â— ë‰´ìŠ¤ í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []

    finally:
        if driver:
            driver.quit()

def crawl_blog(keyword):
    """
    ë„¤ì´ë²„ ë¸”ë¡œê·¸ì—ì„œ í‚¤ì›Œë“œ ê´€ë ¨ ì œëª© 10ê°œ í¬ë¡¤ë§ + í•µì‹¬ HTML ì¼ë¶€ ì €ì¥
    """
    print(f"[í¬ë¡¤ë§ ì‹œì‘] ë¸”ë¡œê·¸ í‚¤ì›Œë“œ: {keyword}")
    driver = None

    try:
        driver = get_driver()
        search_url = f"https://search.naver.com/search.naver?query={keyword}"
        driver.get(search_url)

        # ğŸ“Œ "ë¸”ë¡œê·¸" íƒ­ í´ë¦­ ì‹œë„ (ì‡¼í•‘, ìŒì•… ìš°ì„  ë…¸ì¶œ ë°©ì§€ìš©)
        try:
            blog_tab = WebDriverWait(driver, 5).until(
                EC.element_to_be_clickable((By.LINK_TEXT, "ë¸”ë¡œê·¸"))
            )
            blog_tab.click()
            print("âœ… ë¸”ë¡œê·¸ íƒ­ í´ë¦­ ì™„ë£Œ")
            time.sleep(2)  # ë Œë”ë§ ì—¬ìœ 
        except Exception as e:
            print(f"âš ï¸ ë¸”ë¡œê·¸ íƒ­ í´ë¦­ ì‹¤íŒ¨, ë¬´ì‹œí•˜ê³  ì§„í–‰: {e}")

        # âœ… ë³€ê²½ëœ ì…€ë ‰í„°: ë¸”ë¡œê·¸ ì œëª© a íƒœê·¸ class = 'title_link'
        WebDriverWait(driver, 15).until(
            EC.presence_of_all_elements_located(
                (By.CSS_SELECTOR, 'a.title_link')  # ğŸ”¥ í•µì‹¬ ë³€ê²½
            )
        )

        titles = driver.find_elements(By.CSS_SELECTOR, 'a.title_link')  # ğŸ”¥ í•µì‹¬ ë³€ê²½
        print(f"[ë¸”ë¡œê·¸ ì œëª© ê°œìˆ˜] {len(titles)}ê°œ ì°¾ìŒ")

        # ğŸ’¡ ì œëª© HTML ì¼ë¶€ ì €ì¥ (ë””ë²„ê¹…ìš©)
        with open('blog_debug_partial.html', 'w', encoding='utf-8') as f:
            for title in titles[:5]:
                f.write(title.get_attribute('outerHTML') + '\n\n')
        print("âœ… ì£¼ìš” ë¸”ë¡œê·¸ ì œëª© ì¼ë¶€ HTML ì €ì¥ ì™„ë£Œ: blog_debug_partial.html")

        if len(titles) == 0:
            return ["ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë” êµ¬ì²´ì ì¸ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."]

        return [title.text.strip() for title in titles[:10]]

    except Exception as e:
        if driver:
            with open('blog_debug.html', 'w', encoding='utf-8') as f:
                f.write(driver.page_source)
            print("âœ… ì „ì²´ í˜ì´ì§€ HTML ì €ì¥ ì™„ë£Œ: blog_debug.html")
        print(f"â— ë¸”ë¡œê·¸ í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return ["ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."]

    finally:
        if driver:
            driver.quit()
